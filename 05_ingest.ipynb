{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c024346b-7af1-4838-9625-3d9006333016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from functions.utility_functions import create_table_if_not_exists\n",
    "import layer_01_bronze as bronze\n",
    "import layer_02_silver as silver\n",
    "import layer_03_gold as gold\n",
    "\n",
    "# Variables\n",
    "color                       = dbutils.widgets.get(\"color\")\n",
    "job_settings                = json.loads(dbutils.widgets.get(\"job_settings\"))\n",
    "table                       = job_settings['table']\n",
    "settings                    = json.loads(next(Path().glob(f\"./layer_*_{color}/{table}.json\")).read_text())\n",
    "dst_table_name              = settings.get(\"dst_table_name\")\n",
    "\n",
    "# Print job and table settings\n",
    "settings_message = f\"\\n\\nDictionary from {color}_settings.json:\\n\\n\"\n",
    "settings_message += json.dumps(job_settings, indent=4)\n",
    "settings_message += f\"\\n\\nContents of {table}.json:\\n\\n\"\n",
    "settings_message += json.dumps(settings, indent=4)\n",
    "print(settings_message)\n",
    "\n",
    "modules = {\n",
    "    \"bronze\": bronze,\n",
    "    \"silver\": silver,\n",
    "    \"gold\": gold\n",
    "}\n",
    "\n",
    "# One function for pipeline\n",
    "if \"pipeline_function\" in settings:\n",
    "    modname, funcname = settings[\"pipeline_function\"].split(\".\")\n",
    "    pipeline_function = getattr(modules[modname], funcname)\n",
    "    pipeline_function(spark, settings)\n",
    "\n",
    "# Individual functions for each step\n",
    "elif all(k in settings for k in [\"reader_function\", \"transformer_function\", \"writer_function\"]):\n",
    "    modname, funcname = settings[\"reader_function\"].split(\".\")\n",
    "    reader_function = getattr(modules[modname], funcname)\n",
    "\n",
    "    modname, funcname = settings[\"transformer_function\"].split(\".\")\n",
    "    transformer_function = getattr(modules[modname], funcname)\n",
    "\n",
    "    modname, funcname = settings[\"writer_function\"].split(\".\")\n",
    "    writer_function = getattr(modules[modname], funcname)\n",
    "\n",
    "    df = reader_function(spark, settings)\n",
    "    df = transformer_function(spark, settings, df)\n",
    "    create_table_if_not_exists(spark, df, dst_table_name)\n",
    "    query = writer_function(spark, settings, df)\n",
    "else:\n",
    "    raise Exception(f\"Could not find any ingest function name in settings.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_ingest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
