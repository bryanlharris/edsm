{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "9e512f03-1f87-409b-a674-99791a3d5dca",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Add project root to PYTHONPATH to import functions\n",
        "sys.path.append(str(Path(os.getcwd()).resolve().parents[0]))\n",
        "\n",
        "from functions.utility import _extract_owner\n",
        "\n",
        "\n",
        "def get_owner(obj_type: str, name: str, spark) -> str:\n",
        "    if obj_type == \"volume\":\n",
        "        query = f\"DESCRIBE VOLUME {name}\"\n",
        "        try:\n",
        "            df = spark.sql(query)\n",
        "        except Exception as exc:\n",
        "            print(f'Failed to describe {obj_type} {name}: {exc}')\n",
        "            return None\n",
        "        try:\n",
        "            return df.select('owner').first()['owner']\n",
        "        except Exception:\n",
        "            return None\n",
        "    else:\n",
        "        describe_map = {\n",
        "            'table': f'DESCRIBE TABLE EXTENDED {name}',\n",
        "            'schema': f'DESCRIBE SCHEMA EXTENDED {name}',\n",
        "        }\n",
        "        try:\n",
        "            df = spark.sql(describe_map[obj_type])\n",
        "        except Exception as exc:\n",
        "            print(f'Failed to describe {obj_type} {name}: {exc}')\n",
        "            return None\n",
        "        return _extract_owner(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "361cccf1-f5bc-4cd3-9512-9ef1c490fc49",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"owner-check\").getOrCreate()\n",
        "\n",
        "objects = [\n",
        "    (\"volume\", \"edsm.bronze.landing\"),\n",
        "    (\"schema\", \"edsm.bronze\"),\n",
        "    (\"table\", \"edsm.bronze.powerplay\"),\n",
        "]\n",
        "\n",
        "for obj_type, name in objects:\n",
        "    owner = get_owner(obj_type, name, spark)\n",
        "    if owner:\n",
        "        print(f\"{obj_type} {name} owner: {owner}\")\n",
        "    else:\n",
        "        print(f\"{obj_type} {name} owner not found\")\n",
        "\n",
        "spark.stop()\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "path": "",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
