{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400b61c5-648c-4093-ad88-66bb154038dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, TimestampType\n",
    "from pyspark.sql.functions import concat, regexp_extract, date_format, current_timestamp\n",
    "from pyspark.sql.functions import when, col, to_timestamp, to_date, regexp_replace\n",
    "from pyspark.sql.functions import sha2, concat_ws, coalesce, lit, trim, struct\n",
    "from pyspark.sql.functions import to_json, expr, to_utc_timestamp\n",
    "from pyspark.sql.types import StructType, ArrayType\n",
    "from pyspark.sql.functions import transform\n",
    "import re\n",
    "from functions import create_table_if_not_exists, get_function, silver_scd2_transform\n",
    "from functions import read_snapshot_windowed, silver_standard_transform, overwrite_table\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "settings = {\n",
    "    \"read_function\": \"functions.stream_read_table\",\n",
    "    \"transform_function\": \"functions.silver_standard_transform\",\n",
    "    \"write_function\": \"functions.stream_upsert_table\",\n",
    "    \"upsert_function\": \"functions.upsert_microbatch\",\n",
    "    \"src_table_name\": \"edsm.bronze.systemsWithCoordinates\",\n",
    "    \"dst_table_name\": \"edsm.silver.systemsWithCoordinates\",\n",
    "    \"build_history\": \"true\",\n",
    "    \"business_key\": [\n",
    "        \"id\"\n",
    "    ],\n",
    "    \"surrogate_key\": [\n",
    "        \"name\",\n",
    "        \"coords.x\",\n",
    "        \"coords.y\",\n",
    "        \"coords.z\",\n",
    "        \"date\"\n",
    "    ],\n",
    "    \"data_type_map\": {\n",
    "        \"date\": \"timestamp\"\n",
    "    },\n",
    "    \"readStreamOptions\": {},\n",
    "    \"writeStreamOptions\": {\n",
    "        \"mergeSchema\": \"false\",\n",
    "        \"checkpointLocation\": \"/Volumes/edsm/silver/utility/systemsWithCoordinates7days/_checkpoints/\",\n",
    "        \"delta.columnMapping.mode\": \"name\"\n",
    "    },\n",
    "    \"ingest_time_column\": \"derived_ingest_time\"\n",
    "}\n",
    "\n",
    "\n",
    "df = read_snapshot_windowed(spark, settings)\n",
    "df = silver_standard_transform(df, settings, spark)\n",
    "\n",
    "overwrite_table(df, settings, spark)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Python_systemsWithCoordinates",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
