{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "nuid": "00000000-0000-0000-0000-000000000000",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": "",
          "inputWidgets": {},
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          }
        }
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "paths = ['functions', 'pyspark-scripts', 'layer_01_bronze', 'layer_02_silver', 'layer_03_gold']\n",
        "for pattern in ['_rescued_data', 'add_rescued_data']:\n",
        "    print(f'Checking for {pattern} ...')\n",
        "    res = subprocess.run(['grep', '-R', pattern, *paths], capture_output=True, text=True)\n",
        "    lines = [l for l in res.stdout.splitlines() if '/tests/' not in l and '/docs/' not in l and '/utilities/' not in l and '/cleanup/' not in l]\n",
        "    if lines:\n",
        "        for l in lines:\n",
        "            print(l)\n",
        "    else:\n",
        "        print('None found')\n",
        "res = subprocess.run(['grep', '-R', '_rescued_data', '--include', '*.json', 'layer_01_bronze', 'layer_02_silver', 'layer_03_gold'], capture_output=True, text=True)\n",
        "if res.stdout.strip():\n",
        "    print(res.stdout)\n",
        "else:\n",
        "    print('No JSON files reference _rescued_data')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "nuid": "00000000-0000-0000-0000-000000000000",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": "",
          "inputWidgets": {},
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          }
        }
      },
      "outputs": [],
      "source": [
        "def drop_rescued_data_columns(spark, catalog):\n",
        "    spark.sql(f'use catalog {catalog}')\n",
        "    system_schemas = ['information_schema', 'sys']\n",
        "    schemas = [row.databaseName for row in spark.sql(f'SHOW SCHEMAS IN {catalog}').collect()]\n",
        "    for schema in schemas:\n",
        "        if schema in system_schemas:\n",
        "            print(f'Skipping system schema {schema}')\n",
        "            continue\n",
        "        tables = spark.sql(f'SHOW TABLES IN {catalog}.{schema}').filter('isTemporary = false')\n",
        "        view_rows = spark.sql(f'SHOW VIEWS IN {catalog}.{schema}').collect()\n",
        "        views = {row.viewName for row in view_rows}\n",
        "        for row in tables.collect():\n",
        "            name = row.tableName\n",
        "            if name in views:\n",
        "                print(f'Skipping view {catalog}.{schema}.{name}')\n",
        "                continue\n",
        "            columns = spark.table(f'{catalog}.{schema}.{name}').columns\n",
        "            if '_rescued_data' in columns:\n",
        "                spark.sql(f'ALTER TABLE {catalog}.{schema}.{name} SET TBLPROPERTIES (delta.columnMapping.mode=\"name\")')\n",
        "                spark.sql(f'ALTER TABLE {catalog}.{schema}.{name} DROP COLUMN _rescued_data')\n",
        "                print(f'Dropped _rescued_data from {catalog}.{schema}.{name}')\n",
        "            else:\n",
        "                print(f'Skipping {catalog}.{schema}.{name}: no _rescued_data')\n",
        "\n",
        "drop_rescued_data_columns(spark, 'edsm')\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": {
        "base_environment": "",
        "environment_version": "3"
      },
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "drop_rescued_data",
      "widgets": {}
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}