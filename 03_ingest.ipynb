{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7862117b-bb6b-49b2-b7e3-33e9ebc942f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-labs-dqx==0.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c024346b-7af1-4838-9625-3d9006333016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from functions.utility import get_function, create_bad_records_table, apply_job_type, schema_exists, print_settings\n",
    "from functions.history import build_and_merge_file_history, transaction_history\n",
    "from functions.quality import apply_dqx_checks, count_records\n",
    "\n",
    "# Variables\n",
    "color                       = dbutils.widgets.get('color')\n",
    "job_settings                = json.loads(dbutils.widgets.get('job_settings'))\n",
    "table                       = job_settings['table']\n",
    "settings                    = json.loads(next(Path().glob(f'./layer_*_{color}/{table}.json')).read_text())\n",
    "settings                    = apply_job_type(settings)\n",
    "dst_table_name              = settings['dst_table_name']\n",
    "\n",
    "# Print job and table settings\n",
    "print_settings(job_settings, settings, color, table)\n",
    "\n",
    "# One function for pipeline\n",
    "if 'pipeline_function' in settings:\n",
    "    pipeline_function = get_function(settings['pipeline_function'])\n",
    "    pipeline_function(settings, spark)\n",
    "\n",
    "# Individual functions for each step\n",
    "elif all(k in settings for k in ['read_function', 'transform_function', 'write_function']):\n",
    "    read_function = get_function(settings['read_function'])\n",
    "    transform_function = get_function(settings['transform_function'])\n",
    "    write_function = get_function(settings['write_function'])\n",
    "\n",
    "    df = read_function(settings, spark)\n",
    "    df = transform_function(df, settings, spark)\n",
    "    df, bad_df = apply_dqx_checks(df, settings, spark)\n",
    "    n_bad = count_records(bad_df, spark)\n",
    "    if n_bad > 0:\n",
    "        raise Exception(f\"DQX checks failed: {n_bad} failing records\")\n",
    "    write_function(df, settings, spark)\n",
    "else:\n",
    "    raise Exception(f'Could not find any ingest function name in settings.')\n",
    "\n",
    "# Create a bad records table if bad records files found\n",
    "if color == 'bronze':\n",
    "    create_bad_records_table(settings, spark)\n",
    "\n",
    "# Build history if history settings are provided (default is true for bronze only)\n",
    "history = job_settings.get('history', {})\n",
    "if str(history.get('build_history', 'false')).lower() == 'true':\n",
    "    full_table_name = history.get('full_table_name', dst_table_name)\n",
    "    history_schema = history.get('history_schema')\n",
    "    catalog = full_table_name.split('.')[0]\n",
    "    if history_schema is None:\n",
    "        print('Skipping history build: no history_schema provided')\n",
    "    elif schema_exists(catalog, history_schema, spark):\n",
    "        build_and_merge_file_history(full_table_name, history_schema, spark)\n",
    "        transaction_history(full_table_name, history_schema, spark)\n",
    "    else:\n",
    "        print(f'Skipping history build: schema {catalog}.{history_schema} not found')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_ingest",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}